{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In my opinion, the success of deep neural networks will be determined by how much people expect from them.  If people expect them to solve every single problem, I think that they will disappoint.  Because the internal functions of deep neural networks are so obscure, few, if any, people actually understand why they return the results they do.  This means that, if a network returns incorrect answers, it is difficult to know why it is returning these results and how to change things to fix it.  If, for instance, a deep neural network evaluating images returns an incorrect identification, it will be difficult to fix.  It also means that neural networks struggle to identify images dissimilar to what the network has trained on.  Both of these are major issues for autonomous cars, which need to recognize images quickly and accurately and also recognize images in inclement and changing conditions that the network may have been trained for.  Because of the limitations of a deep neural network, it will likely be unable to address these issues.  \n",
    "On the other hand, deep neural networks have the potential to solve a number of useful problems.  They have radically improved image recognition, even if they have not hit 100% accuracy.  They have also radically improved speech and text processing.  They have also addressed less useful problems, such as playing Go or Chess.  As long as there are problems with large amounts of data and powerful processors to evaluate that data, there will be a role for neural networks in solving problems.  As long as the expectations for deep neural networks are realistic, there is no reason why they cannot continue as a major approach to problem-solving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 185,866\n",
      "Trainable params: 185,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 36s 604us/step - loss: 0.5098 - acc: 0.8130\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 36s 600us/step - loss: 0.3109 - acc: 0.8857\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 36s 601us/step - loss: 0.2646 - acc: 0.9022\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 37s 609us/step - loss: 0.2315 - acc: 0.9143\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 37s 611us/step - loss: 0.2094 - acc: 0.9222\n",
      "10000/10000 [==============================] - 2s 171us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2530519819021225, 0.9102]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Set up the data set\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Test the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "# Best results shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
