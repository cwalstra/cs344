{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook contains the code for the final project of CS 344 Artificial Intelligence at Calvin College.\n",
    "\n",
    "It creates a number of different networks, all aimed at using the Stanford Cars dataset to identify car brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on 22 sty 2018\n",
    "3D Object Representations for Fine-Grained Categorization\n",
    "Jonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei\n",
    "4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013.\n",
    "@author: mgdak\n",
    "'''\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import random\n",
    "import shutil as sh\n",
    "from pprint import pprint\n",
    "import scipy.io as sio\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model, Sequential, model_from_json\n",
    "import shutil as sh\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras import callbacks\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "train_data_dir = 'cars_train'\n",
    "val_data_dir = 'cars_val'\n",
    "nb_train_samples = 1043\n",
    "nb_val_samples = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Global Variable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(learning_rate, lr_decay):\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        \"/home/cjw44/allCars/car_ims/cars_test\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open(\"./carRecognition_finalModel\" + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"./carRecognition_finalModel\" + '.h5')\n",
    "    print('Loaded model from disk')\n",
    "\n",
    "    # evaluate loaded model on test data\n",
    "    sgd = SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "    loaded_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    score = loaded_model.evaluate_generator(test_generator, 3957 / 16, workers=6)\n",
    "    print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1] * 100))\n",
    "\n",
    "# Creates an array with following values: picture name, picture category ID, train/validation label       \n",
    "def readData(matFile):\n",
    "    content = sio.loadmat(matFile)\n",
    "    data = [(_[0][0][:], _[5][0][0], _[6][0][0]) for _ in content['annotations'][0]]\n",
    "    return data\n",
    "\n",
    "\n",
    "# Creates an array of all classes\n",
    "def readClasses(matFile):\n",
    "    content = sio.loadmat(matFile)\n",
    "    classes = [(_[0]) for _ in content['class_names'][0]]\n",
    "    return classes\n",
    "\n",
    "\n",
    "# Movces raw data (pictures) into respective category subfolders with train/validation division \n",
    "def dataPreprocessing(dataDir, labelsFile):\n",
    "    data = readData(labelsFile)\n",
    "    classes = readClasses(labelsFile)\n",
    "    print(\"---------------\")\n",
    "    for recData in data:\n",
    "        if recData[2] == 1:\n",
    "            # validation set\n",
    "            os.makedirs(dataDir + \"/\" + val_data_dir + \"/\" + classes[recData[1] - 1] + \"/\", exist_ok=True)\n",
    "            sh.move(dataDir + \"/\" + recData[0][8:],\n",
    "                    dataDir + \"/\" + val_data_dir + \"/\" + classes[recData[1] - 1] + \"/\" + recData[0][8:])\n",
    "        else:\n",
    "            os.makedirs(dataDir + \"/\" + train_data_dir + \"/\" + classes[recData[1] - 1] + \"/\", exist_ok=True)\n",
    "            sh.move(dataDir + \"/\" + recData[0][8:],\n",
    "                    dataDir + \"/\" + train_data_dir + \"/\" + classes[recData[1] - 1] + \"/\" + recData[0][8:])  # train set\n",
    "\n",
    "\n",
    "# serializes the trained model and its weights\n",
    "def serializeModel(model, fileName):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(fileName + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(fileName + \".h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "def prepareDataGenerators(batchSize, srcImagesDir, labelsFile):\n",
    "    classes = readClasses(labelsFile)\n",
    "    # this is the augmentation configuration used for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # this is the augmentation configuration used for testing:\n",
    "    # only rescaling\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    # this is a generator that will read pictures found in\n",
    "    # subfolers of 'car_ims_dir/train', and indefinitely generate\n",
    "    # batches of augmented image data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        srcImagesDir + \"/\" + train_data_dir + \"/\",  # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 299x299\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical')  # since we use categorical_crossentropy loss, we need categorical labels\n",
    "    # this is a similar generator, for validation data\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        srcImagesDir + \"/\" + val_data_dir + \"/\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical')\n",
    "    return classes, train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions that allow for training and using neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVGG16Architecture(classes, dropoutRate):\n",
    "    # create the base pre-trained model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in enumerate(base_model.layers):\n",
    "        layer[1].trainable = False\n",
    "\n",
    "    # flatten the results from conv block\n",
    "    x = Flatten()(base_model.output)\n",
    "\n",
    "    # add another fully connected layers with batch norm and dropout\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropoutRate)(x)\n",
    "\n",
    "    # add another fully connected layers with batch norm and dropout\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropoutRate)(x)\n",
    "\n",
    "    # add logistic layer with all car classes\n",
    "    predictions = Dense(20, activation='softmax', kernel_initializer='random_uniform',\n",
    "                        bias_initializer='random_uniform', bias_regularizer=regularizers.l2(0.01), name='predictions')(\n",
    "        x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def getVGG19Architecture(classes, dropoutRate):\n",
    "    # create the base pre-trained model\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in enumerate(base_model.layers):\n",
    "        layer[1].trainable = False\n",
    "\n",
    "    # flatten the results from conv block\n",
    "    x = Flatten()(base_model.output)\n",
    "\n",
    "    # add another fully connected layers with batch norm and dropout\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropoutRate)(x)\n",
    "\n",
    "    # add another fully connected layers with batch norm and dropout\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropoutRate)(x)\n",
    "\n",
    "    # add logistic layer with all car classes\n",
    "    predictions = Dense(20, activation='softmax', kernel_initializer='random_uniform',\n",
    "                        bias_initializer='random_uniform', bias_regularizer=regularizers.l2(0.01), name='predictions')(\n",
    "        x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def getInceptionV3Architecture(classes, dropoutRate):\n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # InceptionV3\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu', kernel_initializer='random_uniform', bias_initializer='random_uniform',\n",
    "              bias_regularizer=regularizers.l2(0.01))(x)\n",
    "\n",
    "    # add Dropout regularizer\n",
    "    x = Dropout(dropoutRate)(x)\n",
    "\n",
    "    # and a logistic layer with all car classes\n",
    "    predictions = Dense(len(classes), activation='softmax', kernel_initializer='random_uniform',\n",
    "                        bias_initializer='random_uniform', bias_regularizer=regularizers.l2(0.01), name='predictions')(\n",
    "        x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in enumerate(base_model.layers):\n",
    "        layer[1].trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "def getMyCNN(classes, dropoutRate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(256, 4, activation='relu', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(256, 4, activation='relu'))\n",
    "    model.add(Conv2D(512, 4, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(512, 4, activation='relu'))\n",
    "    model.add(Conv2D(512, 4, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='random_uniform', bias_initializer='random_uniform',\n",
    "                    bias_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "    model.add(Dense(20, activation='softmax', kernel_initializer='random_uniform',\n",
    "                        bias_initializer='random_uniform', bias_regularizer=regularizers.l2(0.01), name='predictions'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that define the neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setLayersToRetrain(model, modelArchitecture):\n",
    "    if modelArchitecture == 'InceptionV3':\n",
    "        # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "        # the first 249 layers and unfreeze the rest:\n",
    "        for layer in model.layers[:249]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        for layer in model.layers[249:]:\n",
    "            layer.trainable = True\n",
    "    elif modelArchitecture == 'VGG16':\n",
    "        # train the last conv block\n",
    "        for layer in model.layers[:15]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        for layer in model.layers[15:]:\n",
    "            layer.trainable = True\n",
    "    elif modelArchitecture == 'VGG19':\n",
    "        # train the last conv block\n",
    "        for layer in model.layers[:17]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        for layer in model.layers[17:]:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        for layer in model.layers[:5]:\n",
    "            layer.trainable = False\n",
    "        for layer in model.layers[5:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "\n",
    "def initialTraining(optimizerLastLayer, noOfEpochs, batchSize, savedModelName, train_generator, validation_generator,\n",
    "                    model, modelArchitecture, lr_decay, learningRate):\n",
    "    # compile the model and train the top layer only\n",
    "\n",
    "    rms = RMSprop(decay=lr_decay, lr=learningRate)\n",
    "    model.compile(optimizer=rms, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    earlystop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto')\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batchSize,\n",
    "        epochs=noOfEpochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_val_samples // batchSize,\n",
    "        callbacks=[earlystop])\n",
    "    plt.plot(history.history['val_acc'], 'r')\n",
    "    plt.plot(history.history['acc'], 'b')\n",
    "    plt.title('Performance of model ' + modelArchitecture)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs No')\n",
    "    plt.savefig(savedModelName + '_initialModel_plot.png')\n",
    "    serializeModel(model, savedModelName + \"_initialModel\")\n",
    "\n",
    "\n",
    "def finetuningTraining(learningRate, noOfEpochs, batchSize, savedModelName, train_generator, validation_generator,\n",
    "                       model, lr_decay):\n",
    "    # we need to recompile the model for these modifications to take effect\n",
    "    # we use SGD with a low learning rate\n",
    "    sgd = SGD(lr=learningRate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    earlystop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto')\n",
    "\n",
    "    # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "    # alongside the top Dense layers\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batchSize,\n",
    "        epochs=noOfEpochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_val_samples // batchSize,        callbacks=[earlystop])\n",
    "    plt.clf()\n",
    "    plt.plot(history.history['val_acc'], 'r')\n",
    "    plt.plot(history.history['acc'], 'b')\n",
    "    plt.savefig(savedModelName + '_finalModel_plot.png')\n",
    "    serializeModel(model, savedModelName + \"_finalModel\")\n",
    "\n",
    "\n",
    "def model(learningRate, optimizerLastLayer, noOfEpochs, batchSize, savedModelName, srcImagesDir, labelsFile,\n",
    "          modelArchitecture, dropoutRate, lr_decay):\n",
    "    classes, train_generator, validation_generator = prepareDataGenerators(batchSize, srcImagesDir, labelsFile)\n",
    "\n",
    "    if modelArchitecture == 'VGG16':\n",
    "        model = getVGG16Architecture(classes, dropoutRate)\n",
    "    elif modelArchitecture == 'VGG19':\n",
    "        model = getVGG19Architecture(classes, dropoutRate)\n",
    "    elif modelArchitecture == \"InceptionV3\":\n",
    "        model = getInceptionV3Architecture(classes, dropoutRate)\n",
    "    else:\n",
    "        model = getMyCNN(classes, dropoutRate)\n",
    "\n",
    "    initialTraining(optimizerLastLayer, noOfEpochs, batchSize, savedModelName, train_generator, validation_generator,\n",
    "                    model, modelArchitecture, lr_decay, learningRate)\n",
    "\n",
    "    setLayersToRetrain(model, modelArchitecture)\n",
    "\n",
    "\n",
    "    finetuningTraining(learningRate, noOfEpochs, batchSize, savedModelName, train_generator, validation_generator,\n",
    "                       model, lr_decay)\n",
    "\n",
    "    evaluate(learningRate, lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    pprint(args)\n",
    "    if args[\"process_data\"]:\n",
    "        dataPreprocessing(args[\"car_ims_dir\"], args[\"car_ims_labels\"])\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model(args[\"learning_rate\"],\n",
    "          args[\"optimizer_last_layer\"],\n",
    "          args[\"no_of_epochs\"],\n",
    "          args[\"batch_size\"],\n",
    "          args[\"saved_model_name\"],\n",
    "          args[\"car_ims_dir\"],\n",
    "          args[\"car_ims_labels\"],\n",
    "          args[\"model\"],\n",
    "          args[\"dropout_rate\"],\n",
    "          args[\"lr_decay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function for starting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'car_ims_dir': '/home/cjw44/allCars/car_ims',\n",
      " 'car_ims_labels': '/home/cjw44/CarData/cars_annos',\n",
      " 'dropout_rate': 0.7,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_decay': 0.0001,\n",
      " 'model': 'MyCNN',\n",
      " 'no_of_epochs': 3,\n",
      " 'optimizer_last_layer': 'RMSPROP',\n",
      " 'process_data': False,\n",
      " 'saved_model_name': 'carRecognition'}\n",
      "Found 1043 images belonging to 20 classes.\n",
      "Found 300 images belonging to 20 classes.\n",
      "WARNING:tensorflow:From /home/cjw44/PycharmProjects/cs344/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 221, 221, 256)     12544     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 110, 110, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 107, 107, 256)     1048832   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 104, 104, 512)     2097664   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 52, 52, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 49, 49, 512)       4194816   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 46, 46, 512)       4194816   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 270848)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               69337344  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 80,891,156\n",
      "Trainable params: 80,891,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/cjw44/PycharmProjects/cs344/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 1717s 107s/step - loss: 14.5757 - acc: 0.0459 - val_loss: 15.3005 - val_acc: 0.0508\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1559s 97s/step - loss: 15.3260 - acc: 0.0492 - val_loss: 15.3671 - val_acc: 0.0466\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1528s 95s/step - loss: 15.2467 - acc: 0.0541 - val_loss: 15.2303 - val_acc: 0.0551\n",
      "Saved model to disk\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 690s 43s/step - loss: 15.2343 - acc: 0.0548 - val_loss: 15.5035 - val_acc: 0.0381\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 677s 42s/step - loss: 15.4202 - acc: 0.0433 - val_loss: 15.1620 - val_acc: 0.0593\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 681s 43s/step - loss: 15.2150 - acc: 0.0560 - val_loss: 15.2986 - val_acc: 0.0508\n",
      "Saved model to disk\n",
      "Found 331 images belonging to 20 classes.\n",
      "Loaded model from disk\n",
      "acc: 5.49%\n"
     ]
    }
   ],
   "source": [
    "args = {}\n",
    "\n",
    "args[\"process_data\"] = False\n",
    "args[\"car_ims_dir\"] = \"/home/cjw44/allCars/car_ims\"\n",
    "args[\"car_ims_labels\"] = \"/home/cjw44/CarData/cars_annos\"\n",
    "args[\"learning_rate\"] = 0.001\n",
    "args[\"dropout_rate\"] = 0.7\n",
    "args[\"lr_decay\"] = 1e-4\n",
    "args[\"optimizer_last_layer\"] = \"RMSPROP\"  # options: ['ADAGRAD', 'ADADELTA', 'ADAM', 'RMSPROP', 'MOM']\n",
    "args[\"model\"] = \"MyCNN\" # options: ['VGG19', 'VGG16', 'InceptionV3', \"MyCNN\"]\n",
    "args[\"no_of_epochs\"] = 3\n",
    "args[\"batch_size\"] = 64\n",
    "args[\"saved_model_name\"] = \"carRecognition\"\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'car_ims_dir': '/home/cjw44/allCars/car_ims',\n",
      " 'car_ims_labels': '/home/cjw44/CarData/cars_annos',\n",
      " 'dropout_rate': 0.7,\n",
      " 'learning_rate': 0.001,\n",
      " 'lr_decay': 0.0001,\n",
      " 'model': 'VGG16',\n",
      " 'no_of_epochs': 10,\n",
      " 'optimizer_last_layer': 'RMSPROP',\n",
      " 'process_data': False,\n",
      " 'saved_model_name': 'carRecognition'}\n",
      "Found 1043 images belonging to 20 classes.\n",
      "Found 300 images belonging to 20 classes.\n",
      "WARNING:tensorflow:From /home/cjw44/PycharmProjects/cs344/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 20)                81940     \n",
      "=================================================================\n",
      "Total params: 134,375,252\n",
      "Trainable params: 119,644,180\n",
      "Non-trainable params: 14,731,072\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 197s 12s/step - loss: 6.8111 - acc: 0.1553 - val_loss: 9.4289 - val_acc: 0.1875\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 177s 11s/step - loss: 4.5777 - acc: 0.3343 - val_loss: 13.3194 - val_acc: 0.0763\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 182s 11s/step - loss: 3.3022 - acc: 0.4661 - val_loss: 7.0381 - val_acc: 0.3347\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 177s 11s/step - loss: 2.8038 - acc: 0.5241 - val_loss: 4.9883 - val_acc: 0.3686\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 174s 11s/step - loss: 2.4094 - acc: 0.6050 - val_loss: 4.9469 - val_acc: 0.4068\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 186s 12s/step - loss: 2.1023 - acc: 0.6436 - val_loss: 5.3556 - val_acc: 0.4023\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 190s 12s/step - loss: 1.7169 - acc: 0.6790 - val_loss: 3.7660 - val_acc: 0.5169\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 183s 11s/step - loss: 1.6636 - acc: 0.6962 - val_loss: 6.8243 - val_acc: 0.3729\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 179s 11s/step - loss: 1.3621 - acc: 0.7426 - val_loss: 4.0073 - val_acc: 0.4788\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 184s 11s/step - loss: 1.3302 - acc: 0.7666 - val_loss: 4.3088 - val_acc: 0.5127\n",
      "Saved model to disk\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 208s 13s/step - loss: 0.9626 - acc: 0.8129 - val_loss: 4.9784 - val_acc: 0.4492\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 211s 13s/step - loss: 0.6886 - acc: 0.8389 - val_loss: 4.6219 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 202s 13s/step - loss: 0.8794 - acc: 0.8329 - val_loss: 4.0710 - val_acc: 0.5297\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 210s 13s/step - loss: 0.5756 - acc: 0.8799 - val_loss: 4.2188 - val_acc: 0.5127\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 216s 14s/step - loss: 0.3972 - acc: 0.8987 - val_loss: 6.1615 - val_acc: 0.4153\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 211s 13s/step - loss: 0.3272 - acc: 0.9236 - val_loss: 3.7388 - val_acc: 0.5678\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 206s 13s/step - loss: 0.2775 - acc: 0.9381 - val_loss: 2.6556 - val_acc: 0.6406\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 208s 13s/step - loss: 0.2919 - acc: 0.9381 - val_loss: 2.4981 - val_acc: 0.6737\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 208s 13s/step - loss: 0.1798 - acc: 0.9520 - val_loss: 1.8817 - val_acc: 0.6780\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 206s 13s/step - loss: 0.2343 - acc: 0.9357 - val_loss: 3.1385 - val_acc: 0.5890\n",
      "Saved model to disk\n",
      "Found 331 images belonging to 20 classes.\n",
      "Loaded model from disk\n",
      "acc: 55.84%\n"
     ]
    }
   ],
   "source": [
    "args = {}\n",
    "\n",
    "args[\"process_data\"] = False\n",
    "args[\"car_ims_dir\"] = \"/home/cjw44/allCars/car_ims\"\n",
    "args[\"car_ims_labels\"] = \"/home/cjw44/CarData/cars_annos\"\n",
    "args[\"learning_rate\"] = 0.001\n",
    "args[\"dropout_rate\"] = 0.7\n",
    "args[\"lr_decay\"] = 1e-4\n",
    "args[\"optimizer_last_layer\"] = \"RMSPROP\"  # options: ['ADAGRAD', 'ADADELTA', 'ADAM', 'RMSPROP', 'MOM']\n",
    "args[\"model\"] = \"VGG16\" # options: ['VGG19', 'VGG16', 'InceptionV3', \"MyCNN\"]\n",
    "args[\"no_of_epochs\"] = 10\n",
    "args[\"batch_size\"] = 64\n",
    "args[\"saved_model_name\"] = \"carRecognition\"\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
